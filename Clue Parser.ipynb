{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clue Generator\n",
    "\n",
    "Scrape MadGab clues from a variety of sources. Remove any extra characters, make sure all clues are valid, write to file with category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General functions and setup\n",
    "all_phrases = []\n",
    "\n",
    "with open(\"madgab/word_to_phonemes.json\") as file:\n",
    "        word_to_phoneme = json.load(file)\n",
    "\n",
    "def process_phrases(phrases):\n",
    "    \"\"\" \n",
    "    Process the passed in phrases in the following ways\n",
    "    \n",
    "    1. Remove everything other than letters and apostraphes\n",
    "    2. Make sure the word count is in [2,5]\n",
    "    3. Make sure every word is in the phoneme dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    def valid_phrase(phrase):\n",
    "        phrase = phrase.lower()\n",
    "        phrase_clean = re.sub(r\"[^a-zA-Z '\\.]\", \"\", phrase)\n",
    "        if len(phrase_clean.split(\" \")) != len(phrase.split(\" \")):\n",
    "            return False\n",
    "        words = phrase_clean.split(\" \")\n",
    "        if not 2 <= len(words) <= 5:\n",
    "            return False\n",
    "        return all([word in word_to_phoneme for word in words])\n",
    "    \n",
    "    phrases = [re.sub(r\"[^a-zA-Z '\\.]\", \"\", phrase) for phrase in phrases if valid_phrase(phrase)]\n",
    "    return list(set(phrases))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Phrases\n",
    "\n",
    "https://www.phrases.org.uk/meanings/phrases-and-sayings-list.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_page = requests.get(\"https://www.phrases.org.uk/meanings/phrases-and-sayings-list.html\")\n",
    "phrases_soup = BeautifulSoup(phrases_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A bird in the hand is worth two in the bush',\n",
       " 'A bunch of fives',\n",
       " 'A chain is only as strong as its weakest link',\n",
       " 'A change is as good as a rest',\n",
       " 'A countenance more in sorrow than in anger',\n",
       " 'A Daniel come to judgement',\n",
       " 'A diamond in the rough',\n",
       " 'A diamond is forever',\n",
       " 'A different kettle of fish',\n",
       " 'A dish fit for the gods']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = [elem.find('a').text for elem in phrases_soup.find_all(\"p\", {\"class\": \"phrase-list\"})]\n",
    "phrases[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processsed_phrases = process_phrases(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with phrases: 1486\n"
     ]
    }
   ],
   "source": [
    "all_phrases += [(phrase, \"General Expression\") for phrase in processsed_phrases]\n",
    "print(f\"All phrases with phrases: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographic Locations\n",
    "\n",
    "https://www.listchallenges.com/print-list/13033  \n",
    "https://www.listchallenges.com/print-list/81758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/places.txt\", \"r\") as file:\n",
    "    places = [place.strip() for place in file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processsed_places = process_phrases(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Florence Cathedral',\n",
       " 'Havana Cuba',\n",
       " 'Freedom Tower Ground Zero',\n",
       " 'Blue Lagoon',\n",
       " 'Lugano Switzerland',\n",
       " 'Cologne Cathedral',\n",
       " 'Petronas Twin Towers',\n",
       " 'Doha Qatar',\n",
       " 'Lausanne Switzerland',\n",
       " 'Gateway Arch']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processsed_places[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with locations: 1795\n"
     ]
    }
   ],
   "source": [
    "all_phrases += [(phrase, \"Geographic Location\") for phrase in processsed_places]\n",
    "print(f\"All phrases with locations: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies\n",
    "\n",
    "https://www.imdb.com/list/ls055592025/  \n",
    "https://www.filmsite.org/boxoffice.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_page = requests.get(\"https://www.imdb.com/list/ls055592025/\")\n",
    "movie_soup = BeautifulSoup(movie_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Godfather',\n",
       " 'The Shawshank Redemption',\n",
       " \"Schindler's List\",\n",
       " 'Raging Bull',\n",
       " 'Casablanca',\n",
       " 'Citizen Kane',\n",
       " 'Gone with the Wind',\n",
       " 'The Wizard of Oz',\n",
       " \"One Flew Over the Cuckoo's Nest\",\n",
       " 'Lawrence of Arabia']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = [elem.find('a').text for elem in movie_soup.find_all(\"h3\", {\"class\": \"lister-item-header\"})]\n",
    "movies[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"clues_temp/movies.txt\", \"w+\") as file:\\n    file.write(\"\\n\".join(movies))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"clues_temp/movies.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join(movies))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/movies.txt\", \"r\") as file:\n",
    "    movies_full = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with movies: 1893\n"
     ]
    }
   ],
   "source": [
    "processed_movies = process_phrases(movies_full)\n",
    "all_phrases += [(phrase, \"Movie\") for phrase in processed_movies]\n",
    "print(f\"All phrases with movies: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TV Shows\n",
    "\n",
    "https://www.imdb.com/list/ls066095353/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_page = requests.get(\"https://www.imdb.com/list/ls066095353/\")\n",
    "tv_soup = BeautifulSoup(tv_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Sopranos',\n",
       " 'The Wire',\n",
       " 'Breaking Bad',\n",
       " 'Mad Men',\n",
       " 'Seinfeld',\n",
       " 'The Simpsons',\n",
       " 'The Twilight Zone',\n",
       " 'Saturday Night Live',\n",
       " 'All in the Family',\n",
       " 'The Daily Show']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv = [elem.find('a').text for elem in tv_soup.find_all(\"h3\", {\"class\": \"lister-item-header\"})]\n",
    "tv[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"clues_temp/tv.txt\", \"w+\") as file:\\n    file.write(\"\\n\".join(tv))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"clues_temp/tv.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join(tv))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/tv.txt\", \"r\") as file:\n",
    "    tv_full = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with tv: 1954\n"
     ]
    }
   ],
   "source": [
    "processed_tv = process_phrases(tv_full)\n",
    "all_phrases += [(phrase, \"TV Show\") for phrase in processed_tv]\n",
    "print(f\"All phrases with tv: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Musical Artists\n",
    "\n",
    "https://www.billboard.com/charts/greatest-hot-100-artists  \n",
    "https://en.wikipedia.org/wiki/List_of_best-selling_music_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_page = requests.get(\"https://www.billboard.com/charts/greatest-hot-100-artists\")\n",
    "music_soup = BeautifulSoup(music_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe Beatles\\n',\n",
       " '\\nMadonna\\n',\n",
       " '\\nElton John\\n',\n",
       " '\\nElvis Presley\\n',\n",
       " '\\nMariah Carey\\n',\n",
       " '\\nStevie Wonder\\n',\n",
       " '\\nJanet Jackson\\n',\n",
       " '\\nMichael Jackson\\n',\n",
       " '\\nWhitney Houston\\n',\n",
       " '\\nRihanna\\n']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music = [elem.find('a').text for elem in music_soup.find_all(\"span\", {\"class\": \"chart-list-item__title-text\"}) if elem and elem.find('a')]\n",
    "music[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"clues_temp/music.txt\", \"w+\") as file:\\n    file.write(\"\\n\".join(music))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"clues_temp/music.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join(music))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/music.txt\", \"r\") as file:\n",
    "    music_full = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with musical artists: 2054\n"
     ]
    }
   ],
   "source": [
    "processed_music = process_phrases(music_full)\n",
    "all_phrases += [(phrase, \"Musical Artists\") for phrase in processed_music]\n",
    "print(f\"All phrases with musical artists: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Songs\n",
    "\n",
    "https://www.billboard.com/articles/news/hot-100-turns-60/8468142/hot-100-all-time-biggest-hits-songs-list  \n",
    "https://en.wikipedia.org/wiki/List_of_best-selling_singles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_page = requests.get(\"https://www.billboard.com/articles/news/hot-100-turns-60/8468142/hot-100-all-time-biggest-hits-songs-list\")\n",
    "song_soup = BeautifulSoup(song_page.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Meet Our Pop Experts!',\n",
       " 'Diane Warren: ',\n",
       " 'The Twist',\n",
       " 'Smooth',\n",
       " 'Mack the Knife',\n",
       " 'Uptown Funk! ',\n",
       " 'How Do I Live',\n",
       " 'Party Rock Anthem',\n",
       " 'I Gotta Feeling',\n",
       " 'Macarena (Bayside Boys Mix)']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = [elem.find('strong').text for elem in song_soup.find_all(\"p\") if elem.find('strong')]\n",
    "song[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"clues_temp/song.txt\", \"w+\") as file:\\n    file.write(\"\\n\".join(song))\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"clues_temp/song.txt\", \"w+\") as file:\n",
    "    file.write(\"\\n\".join(song))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/song.txt\", \"r\") as file:\n",
    "    song_full = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with song: 2241\n"
     ]
    }
   ],
   "source": [
    "processed_song = process_phrases(song_full)\n",
    "all_phrases += [(phrase, \"Song\") for phrase in processed_song]\n",
    "print(f\"All phrases with song: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Famous People\n",
    "\n",
    "https://www.biographyonline.net/people/famous-100.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/people.txt\", \"r\") as file:\n",
    "    people = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with people: 2345\n"
     ]
    }
   ],
   "source": [
    "processed_people = process_phrases(people)\n",
    "all_phrases += [(phrase, \"People\") for phrase in processed_people]\n",
    "print(f\"All phrases with people: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books \n",
    "\n",
    "https://en.wikipedia.org/wiki/List_of_best-selling_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_temp/books.txt\", \"r\") as file:\n",
    "    books_full = file.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phrases with books: 2456\n"
     ]
    }
   ],
   "source": [
    "processed_book = process_phrases(books_full)\n",
    "all_phrases += [(phrase, \"Book\") for phrase in processed_book]\n",
    "print(f\"All phrases with books: {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"clues_full.txt\", \"w+\") as file:\n",
    "    for phrase in all_phrases:\n",
    "        file.write(f\"{phrase[0]} | {phrase[1]}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
